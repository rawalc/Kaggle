source('~/Kaggle/Kaggle_LibertyMutual/src/ScriptRandomForest.R')
source('~/Kaggle/Kaggle_LibertyMutual/src/ScriptRandomForest.R')
cat("\n Making predictions for unlabelled data\n")
source('~/Kaggle/Kaggle_LibertyMutual/src/ScriptXgBoost.R')
source('~/Kaggle/Kaggle_LibertyMutual/src/ScriptXgBoost.R')
## Copied from https://github.com/dmlc/xgboost/blob/master/R-package/demo/custom_objective.R
logregobjective <- function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
preds <- 1/(1 + exp(-preds))
grad <- preds - labels
hess <- preds * (1 - preds)
return(list(grad = grad, hess = hess))
}
params=list(booster="gbtree",objective=logregobjective)
model<-xgb.train(data=detailedTrain,max.depth=5,eta=0.1,
nthread=4,nround=150,
watchlist=watchlist, params=params, verbose=1)
cat("Making predictions for unlabelled data\n")
unknownDataFeatures<-sparse.model.matrix(~.-1,unknownData[,2:33])
submission <- data.frame(Id=unknownData$Id)
submission$Hazard <- predict(model, unknownDataFeatures)
write_csv(submission, "submission8.csv")
# cat("Plotting variable importance\n")
# imp <- importance(rf, type=1)
# featureImportance <- data.frame(Feature=row.names(imp), Importance=imp[,1])
# varImpPlot(rf)
######################## Feature Importance #######################
importance_matrix <- xgb.importance(features@Dimnames[[2]], model = model)
xgb.plot.importance(importance_matrix)
# save.image()
